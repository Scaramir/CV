{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":75176,"databundleVersionId":8252256,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets\nfrom torchvision.io import read_image\n\nclass XRayImageDataset(Dataset):\n    \n    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.transform = transform # do we need this?\n        self.target_transform = target_transform\n        self.compute_mean_std()\n\n    def compute_mean_std(self):\n        #dataset = datasets.ImageFolder(root=self.img_dir)\n        #images = torch.cat([img for img, _ in dataset], dim=0)\n        means = []\n        stds = []\n        for filename in tqdm(os.listdir(self.img_dir)):\n            img = read_image(os.path.join(self.img_dir, filename)) / 255\n            mean, std = torch.std_mean(img)\n            means.append(mean)\n            stds.append(std)\n            #print(img)\n        #images = torch.cat([(read_image(os.path.join(self.img_dir, filename)) / 255) for filename in os.listdir(self.img_dir)])\n        #self.mean, self.std = torch.std_mean(images, dim=0, keepdim=False)\n        self.mean = np.mean(means)\n        self.std = np.mean(stds)\n        \n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n        image = read_image(img_path) # PyTorch function, no need to change\n        label = self.img_labels.iloc[idx, 2] # class_id column\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        return image, label","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-02T12:24:46.275021Z","iopub.execute_input":"2024-05-02T12:24:46.275382Z","iopub.status.idle":"2024-05-02T12:24:46.286735Z","shell.execute_reply.started":"2024-05-02T12:24:46.275351Z","shell.execute_reply":"2024-05-02T12:24:46.285601Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# print the head of the label csv\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nROOT = \"/kaggle/input/amia-public-challenge-2024\"\n\ntest_img_path = ROOT + \"/test/test\"\ntrain_img_path = ROOT + \"/train/train\"\n\ntest_annot_path = ROOT + \"/test.csv\"\ntrain_annot_path = ROOT + \"/train.csv\"\n\nprint(test_img_path)\n\ntrain_data = XRayImageDataset(train_annot_path, train_img_path)\nprint(f'Training images: mean {train_data.mean}, std {train_data.std}')\ntest_data = XRayImageDataset(test_annot_path, test_img_path)\nprint(f'Testing images: mean {test_data.mean}, std {test_data.std}')\n#train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)\n#test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T12:27:45.793600Z","iopub.execute_input":"2024-05-02T12:27:45.793945Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"/kaggle/input/amia-public-challenge-2024/test/test\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 4293/8573 [02:15<03:39, 19.47it/s]","output_type":"stream"}]}]}