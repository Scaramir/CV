{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":75176,"databundleVersionId":8252256,"sourceType":"competition"}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom torchinfo import summary\nimport torch.nn as nn\nfrom PIL import Image\n\n# Load a pre-trained ResNet-18 model\nmodel = models.resnet18(weights='ResNet18_Weights.IMAGENET1K_V1')\n\n# Modify the first convolutional layer to accept 1-channel input\nmodel.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n# Get the number of features in the last layer\nnum_features = model.fc.in_features\n\n# Modify the last fully connected layer to have the same number of output classes as your dataset\nmodel.fc = nn.Linear(num_features, 15)\n\nsummary(model)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-23T15:46:08.600943Z","iopub.execute_input":"2024-05-23T15:46:08.601635Z","iopub.status.idle":"2024-05-23T15:46:12.015883Z","shell.execute_reply.started":"2024-05-23T15:46:08.601598Z","shell.execute_reply":"2024-05-23T15:46:12.015118Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\nResNet                                   --\n├─Conv2d: 1-1                            3,136\n├─BatchNorm2d: 1-2                       128\n├─ReLU: 1-3                              --\n├─MaxPool2d: 1-4                         --\n├─Sequential: 1-5                        --\n│    └─BasicBlock: 2-1                   --\n│    │    └─Conv2d: 3-1                  36,864\n│    │    └─BatchNorm2d: 3-2             128\n│    │    └─ReLU: 3-3                    --\n│    │    └─Conv2d: 3-4                  36,864\n│    │    └─BatchNorm2d: 3-5             128\n│    └─BasicBlock: 2-2                   --\n│    │    └─Conv2d: 3-6                  36,864\n│    │    └─BatchNorm2d: 3-7             128\n│    │    └─ReLU: 3-8                    --\n│    │    └─Conv2d: 3-9                  36,864\n│    │    └─BatchNorm2d: 3-10            128\n├─Sequential: 1-6                        --\n│    └─BasicBlock: 2-3                   --\n│    │    └─Conv2d: 3-11                 73,728\n│    │    └─BatchNorm2d: 3-12            256\n│    │    └─ReLU: 3-13                   --\n│    │    └─Conv2d: 3-14                 147,456\n│    │    └─BatchNorm2d: 3-15            256\n│    │    └─Sequential: 3-16             8,448\n│    └─BasicBlock: 2-4                   --\n│    │    └─Conv2d: 3-17                 147,456\n│    │    └─BatchNorm2d: 3-18            256\n│    │    └─ReLU: 3-19                   --\n│    │    └─Conv2d: 3-20                 147,456\n│    │    └─BatchNorm2d: 3-21            256\n├─Sequential: 1-7                        --\n│    └─BasicBlock: 2-5                   --\n│    │    └─Conv2d: 3-22                 294,912\n│    │    └─BatchNorm2d: 3-23            512\n│    │    └─ReLU: 3-24                   --\n│    │    └─Conv2d: 3-25                 589,824\n│    │    └─BatchNorm2d: 3-26            512\n│    │    └─Sequential: 3-27             33,280\n│    └─BasicBlock: 2-6                   --\n│    │    └─Conv2d: 3-28                 589,824\n│    │    └─BatchNorm2d: 3-29            512\n│    │    └─ReLU: 3-30                   --\n│    │    └─Conv2d: 3-31                 589,824\n│    │    └─BatchNorm2d: 3-32            512\n├─Sequential: 1-8                        --\n│    └─BasicBlock: 2-7                   --\n│    │    └─Conv2d: 3-33                 1,179,648\n│    │    └─BatchNorm2d: 3-34            1,024\n│    │    └─ReLU: 3-35                   --\n│    │    └─Conv2d: 3-36                 2,359,296\n│    │    └─BatchNorm2d: 3-37            1,024\n│    │    └─Sequential: 3-38             132,096\n│    └─BasicBlock: 2-8                   --\n│    │    └─Conv2d: 3-39                 2,359,296\n│    │    └─BatchNorm2d: 3-40            1,024\n│    │    └─ReLU: 3-41                   --\n│    │    └─Conv2d: 3-42                 2,359,296\n│    │    └─BatchNorm2d: 3-43            1,024\n├─AdaptiveAvgPool2d: 1-9                 --\n├─Linear: 1-10                           7,695\n=================================================================\nTotal params: 11,177,935\nTrainable params: 11,177,935\nNon-trainable params: 0\n================================================================="},"metadata":{}}]},{"cell_type":"code","source":"ROOT = \"/kaggle/input/amia-public-challenge-2024\"\n\ntest_img_path = ROOT + \"/test/test\"\ntrain_img_path = ROOT + \"/train/train\"\n\ntest_annot_path = ROOT + \"/test.csv\"\ntrain_annot_path = ROOT + \"/train.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:46:12.017461Z","iopub.execute_input":"2024-05-23T15:46:12.017837Z","iopub.status.idle":"2024-05-23T15:46:12.022283Z","shell.execute_reply.started":"2024-05-23T15:46:12.017811Z","shell.execute_reply":"2024-05-23T15:46:12.021357Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nclass XRayImageDataset(Dataset):\n    \n    def __init__(self, annotations_file, img_dir, mean=None, std=None,transform_norm=None, target_transform=None):\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.mean = mean\n        self.std = std\n        self.transform_norm = transforms.Compose([\n            transforms.Resize((224,224),antialias=True),\n            transforms.Normalize(self.mean, self.std)\n        ])\n        self.target_transform = target_transform    \n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])+'.png'\n        image = read_image(img_path) # PyTorch function, no need to change\n        label = self.img_labels.iloc[idx, 2] # class_id column\n        image = self.transform_norm(image.float())\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:46:12.023460Z","iopub.execute_input":"2024-05-23T15:46:12.023777Z","iopub.status.idle":"2024-05-23T15:46:12.335045Z","shell.execute_reply.started":"2024-05-23T15:46:12.023749Z","shell.execute_reply":"2024-05-23T15:46:12.334304Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets, transforms\nfrom torchvision.io import read_image\n\ntrain_data = XRayImageDataset(train_annot_path, train_img_path, 0.04664242120787185, 0.10213025072799406)\nprint(f'Training images: mean {train_data.mean}, std {train_data.std}')\n\ntrain_dataloader = DataLoader(train_data, batch_size=12, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:46:12.336082Z","iopub.execute_input":"2024-05-23T15:46:12.336522Z","iopub.status.idle":"2024-05-23T15:46:12.415524Z","shell.execute_reply.started":"2024-05-23T15:46:12.336498Z","shell.execute_reply":"2024-05-23T15:46:12.414611Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Training images: mean 0.04664242120787185, std 0.10213025072799406\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data = XRayImageDataset(test_annot_path, test_img_path, 0.07274098403775907, 0.16118353533641264)\nprint(f'Testing images: mean {test_data.mean}, std {test_data.std}')\n\ntest_dataloader = DataLoader(test_data, batch_size=12, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:46:12.418227Z","iopub.execute_input":"2024-05-23T15:46:12.419185Z","iopub.status.idle":"2024-05-23T15:46:12.439940Z","shell.execute_reply.started":"2024-05-23T15:46:12.419156Z","shell.execute_reply":"2024-05-23T15:46:12.439080Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Testing images: mean 0.07274098403775907, std 0.16118353533641264\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.optim as optim\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Number of epochs\nnum_epochs = 2\n\n# Device configuration (use GPU if available)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\n# Training and evaluation loop\nfor epoch in range(num_epochs):\n    # Training phase\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for inputs, labels in tqdm(train_dataloader, desc=f'Train Ep. 1 {epoch+1}'):\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # Zero the parameter gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimize\n        loss.backward()\n        optimizer.step()\n\n        # Statistics\n        running_loss += loss.item() * inputs.size(0)\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    epoch_loss = running_loss / total\n    epoch_acc = correct / total\n\n    print(f'Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}')\n\n    # Evaluation phase\n    model.eval()\n    test_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for inputs, labels in tqdm(test_dataloader, desc=f'Evaluating Epoch {epoch+1}/{num_epochs}'):\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # Forward pass\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            # Statistics\n            test_loss += loss.item() * inputs.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    test_loss /= total\n    test_acc = correct / total\n\n    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n\nprint('Training complete')","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:46:12.440978Z","iopub.execute_input":"2024-05-23T15:46:12.441254Z","iopub.status.idle":"2024-05-23T16:00:08.861574Z","shell.execute_reply.started":"2024-05-23T15:46:12.441231Z","shell.execute_reply":"2024-05-23T16:00:08.860147Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Train Ep. 1 1: 100%|██████████| 3828/3828 [13:54<00:00,  4.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.6951, Train Acc: 0.4496\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Epoch 1/2:   0%|          | 0/1833 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(test_dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluating Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     54\u001b[0m         inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[3], line 25\u001b[0m, in \u001b[0;36mXRayImageDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     23\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_labels\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     24\u001b[0m image \u001b[38;5;241m=\u001b[39m read_image(img_path) \u001b[38;5;66;03m# PyTorch function, no need to change\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# class_id column\u001b[39;00m\n\u001b[1;32m     26\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_norm(image\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:1183\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4211\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   4192\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4193\u001b[0m \u001b[38;5;124;03mQuickly retrieve single value at passed column and index.\u001b[39;00m\n\u001b[1;32m   4194\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4208\u001b[0m \u001b[38;5;124;03m`self.columns._index_as_unique`; Caller is responsible for checking.\u001b[39;00m\n\u001b[1;32m   4209\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m takeable:\n\u001b[0;32m-> 4211\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[index]\n\u001b[1;32m   4214\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_item_cache(col)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4008\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   4004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m   4006\u001b[0m \u001b[38;5;66;03m# icol\u001b[39;00m\n\u001b[1;32m   4007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4008\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   4010\u001b[0m     col_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39miget(i)\n\u001b[1;32m   4011\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_box_col_values(col_mgr, i)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:5389\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(key) \u001b[38;5;129;01mor\u001b[39;00m is_float(key):\n\u001b[1;32m   5387\u001b[0m     \u001b[38;5;66;03m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[1;32m   5388\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mcast_scalar_indexer(key)\n\u001b[0;32m-> 5389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   5392\u001b[0m     \u001b[38;5;66;03m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[1;32m   5393\u001b[0m     \u001b[38;5;66;03m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[1;32m   5394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_slice(key)\n","\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 1"],"ename":"IndexError","evalue":"index 2 is out of bounds for axis 0 with size 1","output_type":"error"}]}]}