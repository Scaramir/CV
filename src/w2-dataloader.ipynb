{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":75176,"databundleVersionId":8252256,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets, transforms\nfrom torchvision.io import read_image\n\nclass XRayImageDataset(Dataset):\n    \n    def __init__(self, annotations_file, img_dir, transform_norm=None, target_transform=None):\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.mean, self.std = self.compute_mean_std()\n        self.transform_norm = transforms.Compose([\n            transforms.Normalize(self.mean, self.std)\n        ])\n        self.target_transform = target_transform\n\n    def compute_mean_std(self):\n        means = 0\n        stds = 0\n        for filename in tqdm(os.listdir(self.img_dir)):\n            mean, std = torch.std_mean(read_image(os.path.join(self.img_dir, filename)) / 255)\n            means += mean.numpy()\n            stds += std.numpy()\n        mean = means / self.__len__()\n        std = stds / self.__len__()\n        return mean, std\n        \n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n        image = read_image(img_path) # PyTorch function, no need to change\n        label = self.img_labels.iloc[idx, 2] # class_id column\n        if self.transform_norm:\n            image = self.transform_norm(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        return norm_img, label","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-02T13:11:03.404551Z","iopub.execute_input":"2024-05-02T13:11:03.405644Z","iopub.status.idle":"2024-05-02T13:11:03.419419Z","shell.execute_reply.started":"2024-05-02T13:11:03.405591Z","shell.execute_reply":"2024-05-02T13:11:03.417931Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"ROOT = \"/kaggle/input/amia-public-challenge-2024\"\n\ntest_img_path = ROOT + \"/test/test\"\ntrain_img_path = ROOT + \"/train/train\"\n\ntest_annot_path = ROOT + \"/test.csv\"\ntrain_annot_path = ROOT + \"/train.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-05-02T13:01:56.298012Z","iopub.execute_input":"2024-05-02T13:01:56.298472Z","iopub.status.idle":"2024-05-02T13:01:56.305576Z","shell.execute_reply.started":"2024-05-02T13:01:56.298437Z","shell.execute_reply":"2024-05-02T13:01:56.303872Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_data = XRayImageDataset(train_annot_path, train_img_path)\nprint(f'Training images: mean {train_data.mean}, std {train_data.std}')\n\ntrain_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T13:11:06.620110Z","iopub.execute_input":"2024-05-02T13:11:06.620813Z","iopub.status.idle":"2024-05-02T13:13:44.839955Z","shell.execute_reply.started":"2024-05-02T13:11:06.620786Z","shell.execute_reply":"2024-05-02T13:13:44.838310Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"/kaggle/input/amia-public-challenge-2024/test/test\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 8573/8573 [02:38<00:00, 54.21it/s]","output_type":"stream"},{"name":"stdout","text":"Training images: mean 0.04664242120787185, std 0.10213025072799406\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data = XRayImageDataset(test_annot_path, test_img_path)\nprint(f'Testing images: mean {test_data.mean}, std {test_data.std}')\n\ntest_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T13:15:29.844706Z","iopub.execute_input":"2024-05-02T13:15:29.846187Z","iopub.status.idle":"2024-05-02T13:18:20.182689Z","shell.execute_reply.started":"2024-05-02T13:15:29.846123Z","shell.execute_reply":"2024-05-02T13:18:20.181791Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"100%|██████████| 6427/6427 [02:50<00:00, 37.77it/s]","output_type":"stream"},{"name":"stdout","text":"Testing images: mean 0.07274098403775907, std 0.16118353533641264\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}